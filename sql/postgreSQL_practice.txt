0. Connect to the psql console to execute SQL commands for the ls_burger database:
sudo -u postgres psql ls_burger

2. Query to select all customer names from orders:
SELECT customer_name FROM orders;

3. Query to select all orders including a Chocolate Shake:
SELECT * FROM orders WHERE drink = 'Chocolate Shake';

# takeaway: '=' operator in SQL is used for comparisons, not '=='

4. Query to select burder, side, and drink columns for only the order with id 2:
SELECT burger, side, drink FROM orders WHERE id = 2;

5. Query to select all customers that ordered Onion Rings:
SELECT customer_name FROM orders WHERE side = 'Onion Rings';

6. Create new database from the terminal, not the psql console:
sudo -u postgres createdb a_new_database

7. Connect to database created through the psql console & make a new database from w/in the psql console:
sudo -u postgres psql a_new_database    # to connect
CREATE DATABASE another_database;       # to create new db from w/in psql console

8. Switch connection to a different database from within the psql console:
\c another_database

9. Delete a database from within the psql console:
DROP DATABASE a_new_database;
\list                                   # check deletion by listing all current databases

10. Delete a database from the terminal:
sudo -u postgres dropdb another_database

11. Create tables within a database via psql console:
CREATE TABLE countries (
    id serial,                          # each row specifies: column_name data_type optional_constraints
    name varchar(50) UNIQUE NOT NULL,   # varchar() specifies up to a certain # of characters, but doesn't pad string 
    capital varchar(50) NOT NULL,       #      with spaces if the string's length is less than the argument specified
    population integer
);


CREATE TABLE animals (
    id serial,
    name varchar(100) NOT NULL,
    binomial_name varchar(100) NOT NULL,
    max_weight_kg decimal(8,3),         # decimal's 1st argument specifies total # of digits allowed & 2nd argument
    max_age integer,                    #       specifies digits allowed to the right of the decimal point
    conservation_status char(2)
);

12. Update a date_of_birth column to store an actual date instead of a string & add constraint to ensure value:
exists for each row of the column
ALTER TABLE table_name
    ALTER COLUMN date_of_birth
    TYPE date
    USING date_of_birth::date,  # must specify USING clause to clarify conversion of data type & comma separate chained commands
    SET NOT NULL;

13. Updating column to different precision and scale:
ALTER TABLE animals
    ALTER COLUMN max_weight_kg TYPE decimal(10,4);    # USING clause not required when there is a natural conversion

14. Update table to drop an order total column & replace it with 3 new columns:
ALTER TABLE orders
    ADD COLUMN burger_cost decimal(4, 2) DEFAULT 0,
    ADD COLUMN side_cost decimal(4, 2) DEFAULT 0,
    ADD COLUMN drink_cost decimal(4, 2) DEFAULT 0,
    DROP COLUMN order_total;
    
15. Add multiple rows of data to a table:
INSERT INTO countries (name, capital, population)   # id column not specified will get default value
    VALUES ('USA', 'Washington D.C.', 325365189),   # (row1), (row2), row(3);
           ('Germany', 'Berlin', 82349400),
           ('Japan', 'Tokyo', 126672000);

INSERT INTO celebrities (first_name, last_name, occupation, date_of_birth, deceased)
    VALUES ('Frank', 'Sinatra', 'Singer, Actor', '1915-12-12', true)
           ('Tom', 'Cruise', 'Actor', '1962-07-03', DEFAULT);   # can also explicitly specify a row should use column's default value

16. Drop constraints no longer needed:
ALTER TABLE animals
    DROP CONSTRAINT unique_binomial_name;

ALTER TABLE celebrities
    ALTER COLUMN last_naame DROP NOT NULL;    # NOT NULL is always a column constraint 

17. Query country names and capitals sorted by population:
SELECT name, capital
    FROM countries
    ORDER BY population DESC;
    
SELECT name, capital
    FROM countries
    ORDER BY population;    # default sorts ascendingly for numerical columns

18. Query based on population between 70 million (inclusive) and 200 million (exclusive):
SELECT name, capital, population
    FROM countries
    WHERE population >= 70000000 AND population < 200000000;

19. Query to return all records associated with occupations including singing and acting:
SELECT first_name, last_name
    FROM celebrities
    WHERE (occupation LIKE '%Actor%' OR occupation LIKE '%Actress%')
    AND occupation LIKE '%Singer%';

20. Query to find all orders that don't have fries as a side:
SELECT customer_name
    FROM orders
    WHERE side != 'Fries'
    OR side IS NULL;

21. Queries to find the 2 countries with the largest populations:
SELECT name
    FROM countries
    ORDER BY population DESC
    LIMIT 1;            # returns name of country w/ largest populaton only

SELECT name
    FROM countries
    ORDER BY population DESC
    LIMIT 1 OFFSET 1;   # returns name of country w/ 2nd largest population

SELECT name
    FROM countries
    ORDER BY population DESC
    LIMIT 2;            # return the names of the 2 countries with largest populations

22. Query to return the longest capital name:
SELECT capital
    FROM countries
    ORDER BY length(capital) DESC
    LIMIT 1;

23. Query to return the number of animals associated with each conservation status:
SELECT conservation_status, count(id)
    FROM animals
    GROUP BY conservation_status;

24. Query to return average burger cost for all orders that include fries.
SELECT avg(burger_cost)
    FROM orders
    WHERE side ILIKE 'Fries';     # ILIKE ensures case insensitivity

25. Query to return cheapest side order:
SELECT side_cost
    FROM orders
    ORDER BY side_cost
    DESC LIMIT 1;

SELECT min(side_cost)
    FROM orders
    WHERE side IS NOT NULL;

26. Query to return counts of orders that have either fries or onion rings.
SELECT side, count(id)
    FROM orders
    WHERE side ILIKE 'fries'
    OR side ILIKE 'onion rings'
    GROUP BY side;

27. Add columns to table and fill all rows and fill only certain rows:
ALTER TABLE animals
    ADD COLUMN phylum varchar(100),
    ADD COLUMN kingdom varchar(100);

UPDATE animals
    SET phylum = 'Chordata',
    SET kingdom = 'Animalia';

ALTER TABLE countries
    ADD COLUMN continent varchar(50);

UPDATE countries
    SET continent = 'Europe'
    WHERE (name = 'France' OR name = 'Germany');

27. Replace data for specific rows:
UPDATE orders
    SET drink = 'Lemonade'
    WHERE id = 5;

UPDATE orders
    SET side = 'Fries',
    side_cost = 0.99,
    customer_loyalty_points = 13,
    WHERE id = 4;

28. Create a one-to-many relationship between two tables:
CREATE TABLE continents (
    id serial PRIMARY KEY,
    continent_name varchar(50) NOT NULL
);

ALTER TABLE countries
    DROP COLUMN continent;

ALTER TABLE countries
    ADD COLUMN continent_id integer;

ALTER TABLE countries
    ADD FOREIGN KEY (continent_id)
    REFERENCES continents(id);

INSERT INTO continents (id, continent_name)
    VALUES (1, 'Europe'),
           (2, 'North America'),
           (3, 'Asia'),
           (4, 'Africa'),
           (5, 'South America');

INSERT INTO countries (name, capital, population, continent_id)
    VALUES ('France', 'Paris', 67158000, 1),
           ('Brazil', 'Brasilia', 208385000, 5),
           ('Japan', 'Tokyo', 126672000, 3),
           ('USA', 'Washington D.C.', 325365189, 2),
           ('Egypt', 'Cairo', 96308900, 4);

29. Normalize orders table by splitting data into multiple tables:

# one-to-one relationship is created between customer and email address by setting
#  the customer_id as the primary key for the customers table and foreign key of the email_addresses table

CREATE TABLE customers (
    id serial PRIMARY KEY,
    customer_name varchar(100)
);

CREATE TABLE email_addresses (
    customer_id integer PRIMARY KEY,
    customer_email varchar(50),
    FOREIGN KEY (customer_id) 
    REFERENCES customers(id)
    ON DELETE CASCADE       # if customer is deleted then email address is deleted via CASCADE clause
);

INSERT INTO customers (customer_name)
     VALUES ('John Doe'),
            ('Natasha O''Shea');    # need to escape single quote character with a single quote character

INSERT INTO email_addresses (customer_id, customer_email)
     VALUES (1, 'johndoe@this_is_a_fake_email.com'),
            (2, 'natoshea@this_is_a_fake_email.com');

CREATE TABLE products (
     id serial PRIMARY KEY,
     product_name varchar(50),
     product_type varchar(20),
     product_cost numeric(4,2) DEFAULT 0,
     product_loyalty_points integer 
);

INSERT INTO products (product_name, product_cost, product_type, product_loyalty_points)
VALUES ('Burger', 3.00, 'Burger', 10 ),
       ('Cheeseburger', 3.50, 'Burger', 15 ),
       ('Chicken Burger', 4.50, 'Burger', 20 ),
       ('Double Deluxe Burger', 6.00, 'Burger', 30 ),
       ('Fries', 1.20, 'Side', 3 ),
       ('Onion Rings', 1.50, 'Side', 5 ),
       ('Cola', 1.50, 'Drink', 5 ),
       ('Lemonade', 1.50, 'Drink', 5 ),
       ('Vanilla Shake', 2.00, 'Drink', 7 ),
       ('Chocolate Shake', 2.00, 'Drink', 7 ),
       ('Strawberry Shake', 2.00, 'Drink', 7);

DROP TABLE orders;

# recreate orders table with only necessary columns to create one-to-many relationship between
#   customers and orders (order is tied to one customer, but one customer can have many orders)

CREATE TABLE orders (
    id serial PRIMARY KEY,
    customer_id integer NOT NULL,
    order_status varchar(30),
    FOREIGN KEY (customer_id)
        REFERENCES customers(id)
        ON DELETE CASCADE
);

# create order_items table as a reference table that establishes a many-to-many relationship
#  between the orders and products table 

CREATE TABLE order_items (
    id serial PRIMARY KEY,
    order_id integer NOT NULL,
    product_id integer NOT NULL,
    FOREIGN KEY (order_id)
    REFERENCES orders (id)
    ON DELETE CASCADE,
    FOREIGN KEY (product_id)
    REFERENCES products (id)
    ON DELETE CASCADE
);

# order of adding in data matters, so as to not invalidate a NOT NULL condition and raise an exception
INSERT INTO orders (customer_id, order_status)
    VALUES (1, 'Waiting to be processed'),
           (1, 'Processing'),
           (2, 'Waiting to be processed'),
           (2, 'Fulfilled');

INSERT INTO order_items (order_id, product_id)
VALUES (5, 7),
       (6, 6),
       (7, 8),
       (7, 2),
       (7, 3),
       (8, 5),
       (8, 7);

30. Joins:
SELECT countries.name, continents.continent_name
    FROM countries
    INNER JOIN continents    # could've done a left join instead of an inner join to return the same results
        ON countries.continent_id = continents.id;

SELECT singers.first_name, singers.last_name, albums.album_name, albums.release_date,
    FROM singers
    JOIN albums
        ON singers.id = albums.singer_id
    WHERE album.release_date >= '1980-01-01'
    AND albums.release_date < '1990-01-01'
    AND singers.deceased = false
    ORDER BY singers.date_of_birth DESC;

# left join:
SELECT singers.first_name, singers.last_name
    FROM singers
    LEFT JOIN albums
        ON singers.id = albums.singer_id
    WHERE albums.id IS NULL;

# subquery (alternative to a join in some cases, but takes longer in postgresql):
SELECT first_name, last_name
    FROM singers
    WHERE id NOT IN (SELECT singer_id FROM albums);

# multiple joins:
SELECT orders.*, products.*
    FROM orders
    JOIN order_items
        ON orders.id = order_items.order_id
    JOIN products
        ON order_items.product_id = products.id;

# aliasing to shorten query length:
SELECT o.id
    FROM orders AS o
    JOIN order_items AS i
        ON o.id = i.order_id
    JOIN products AS p
        ON i.product_id = p.id
    WHERE p.product_name LIKE 'Fries';

# aliasing to give a descriptor to values returned:
SELECT DISTINCT c.customer_name AS "Customers who ordered Fries"
    FROM customers AS c JOIN orders AS o
        ON c.id = o.customer_id
    JOIN order_items AS i
        ON o.id = i.order_id
    JOIN products AS p
        ON i.product_id = p.id
    WHERE p.product_name = 'Fries';

SELECT sum(p.product_cost)
    FROM customers AS c JOIN orders AS o
        ON c.id = o.customer_id
    JOIN order_items AS i
        ON o.id = i.order_id
    JOIN products AS p
        ON i.product_id = p.id
    WHERE c.customer_name = 'Natasha O''Shea';

SELECT p.product_name, COUNT(i.id)
    FROM products AS p JOIN order_items AS i
        ON p.id = i.product_id
    GROUP BY p.product_name
    ORDER BY p.product_name ASC;

31.Loading an sql file into a database:
sudo -u postgres psql
CREATE DATABASE residents;
\q
sudo -u postgres psql -d residents < sample_residents_data.sql

# more querying practice:
SELECT state, count(id)
    FROM people
    GROUP BY state
    ORDER BY count(id) DESC;

# string manipulation: sorted counts of email domains:
SELECT substring(email
                 FROM (position('@' in email) + 1)
                 FOR length(email)) AS domain, 
        count(id)
    FROM people
    GROUP BY domain
    ORDER BY count DESC;

DELETE FROM people WHERE id = 3399;
DELETE FROM people WHERE state = 'CA';

UPDATE people
    SET given_name = upper(given_name)
    WHERE substring(email
                 FROM (position('@' in email) + 1)
                 FOR length(email)) = 'teleworm.us';

# check capitalization:
SELECT given_name
    FROM people
    WHERE substring(email
                 FROM (position('@' in email) + 1)
                 FOR length(email)) = 'teleworm.us';

32. Creating an sql file to store commands to recreate table:
CREATE TABLE temperatures
    (date date NOT NULL,
    low integer NOT NULL,
    high integer NOT NULL);

INSERT INTO temperatures
    VALUES ('2016-03-01', 34, 43),
           ('2016-03-02', 32, 44),
           ('2016-03-03', 31, 47),
           ('2016-03-04', 33, 42),
           ('2016-03-05', 39, 46),
           ('2016-03-06', 32, 43),
           ('2016-03-07', 29, 32),
           ('2016-03-09', 23, 31),
           ('2016-03-09', 17, 28);

SELECT date, round((high + low)/2, 1) AS avg_temp
    FROM temperatures
    WHERE date >= '2016-03-02';

ALTER TABLE temperatures
    ADD COLUMN rainfall integer DEFAULT 0;

UPDATE temperatures
    SET rainfall = 1 * (((high + low) / 2) - 35)
    WHERE (high + low) / 2 >= 35;

# set rainfall in inches instead of millimeters:
ALTER TABLE temperatures
    ALTER COLUMN rainfall TYPE numeric(6,3);

UPDATE temperatures
    SET rainfall = rainfall * 0.039;

ALTER TABLE temperatures
    RENAME TO weather;

*create SQL file that contains all SQL commands to recreate
the schema and data of the weather table:
pg_dump -d database_name -t weather --inserts > new_file.sql

33. Sequences:
# establishing a new sequence:
CREATE SEQUENCE counter;

# retrieving next value in the sequence:
SELECT nextval('counter');

# deleting a sequence:
DROP SEQUENCE counter;

# sequence of only even numbers:
CREATE SEQUENCE even_counter
    INCREMENT BY 2
    START WITH 2;   # can't set starting value as 0

# Adding auto-incrementing integer primary key column to a table:
ALTER TABLE films ADD COLUMN id serial PRIMARY KEY;

# Remove primary key status of a column while keeping the column's values:
ALTER TABLE films DROP CONSTRAINT films_pkey;

34. More practice working with multiple tables:
# Find the number of different customers that bought tickets to >= 1 event
SELECT count(DISTINCT customers.id)
    FROM customers
    INNER JOIN tickets
        ON customers.id = tickets.customer_id;

# Return the % of customers in database that bought a ticket to >= 1 event
# approach:
#   > left join customers table with the tickets table to return a row for every
#      customer_id and their associated ticket
#    <=> each row associated with a customer that hasn't purchased a ticket
#          will have their corresponding ticket's customer_id column filled with NULL
SELECT concat(CAST(round(count(DISTINCT tickets.customer_id) /
                         count(DISTINCT customers.id)::decimal * 100, 2) AS text), '%')
        AS pct_customers_that_purchased
    FROM customers
    LEFT OUTER JOIN tickets
        ON tickets.customer_id = customers.id;

# Return the all unique event names & number of tickets sold for that respective event
# approach:
#  > events table has unique id column that's referenced as a foreign key in the tickets table
#  > left join from tickets table would return a row for each unique ticket id
SELECT tickets.id AS ticket_id, events.id AS event_id, events.name
    FROM tickets
    LEFT OUTER JOIN events
        ON tickets.event_id = events.id;

#  > returned table from the join needs to be rolled up to the unique event level to calc
#     the number of tickets sold for a specific event
SELECT events.name, count(DISTINCT tickets.id) AS popularity
    FROM tickets
    LEFT OUTER JOIN events
        ON tickets.event_id = events.id
    GROUP BY events.id
    ORDER BY popularity DESC;

# Return customer id, email, and # of events attended for customers that have bought tickets
#  for 3 events
# approach:
#   > tickets relation has event_id column, so only need to merge on tickets' table info to
#      info from the customer relation (don't need any specific info from the events table)
#   > left join from the tickets table would keep all unique ticket rows and merge on corresponding
#        customer info needed for this request, like the customer's email
#   > a customer can purchase multiple tickets for the same event, so in order to find the customers
#      that have bought tickets for 3 unique events, will need to count the unique number of event_ids
#      associated with each customer's tickets after joining the tickets table with the customers table

SELECT customers.id, customers.email, count(DISTINCT tickets.event_id)
    FROM tickets
    LEFT JOIN customers
        ON tickets.customer_id = customers.id
    GROUP BY customers.id
    HAVING count(DISTINCT tickets.event_id) = 3;

# Return a list of all tickets bought by a specific customer email including the event name,
#  the starts_at time, the seat's section name, row, and number

# approach:
#   > merge customers relation with tickets relation to find all tickets associated
#       with the particular customer in scope
#   > tickets relation has event_id and seat_id columns that can be subsequently used
#      to merge on the relevant event name and event start time from the events relation
#      and to merge on the row, number, and section_id fields from the seats relation
#   > using the merged on section_id field, can subsequently merge on the sections table's
#      name field

SELECT events.name AS event, events.starts_at,
       sections.name AS section, seats.row, 
       seats.number AS seat
    FROM customers
    INNER JOIN tickets
        ON customers.id = tickets.customer_id
    LEFT JOIN seats
        ON tickets.seat_id = seats.id
    LEFT JOIN events
        ON tickets.event_id = events.id
    LEFT JOIN sections
        ON seats.section_id = sections.id
    WHERE customers.email = 'gennaro.rath@mcdermott.co';
